library(MASS)
?shuttle
head(shuttle)
levels(shuttle$use)
myShuttle <- shuttle
use2 <- use == "auto"
use2 <- shuttle$use == "auto"
head(use2)
glm(use2, shuttle$wind)
mode(shuttle)
shuttle$use
glm(use2, shuttle$wind)
?glm
glm(use2 ~ shuttle$wind)
summary(glm(use2 ~ shuttle$wind))
summary(glm(use2 ~ shuttle$wind, family = "logit"))
summary(glm(use2 ~ shuttle$wind, family = binomial(link = "logit")))
summary(glm(use2 ~ shuttle$wind, family = binomial)
)
summary(glm(use ~ wind + magn, data = shuttle, family = binomial))
summary(glm(use ~ wind * magn, data = shuttle, family = binomial))
summary(glm(use2 ~ factor(wind) + magn, data = shuttle, family = binomial))
summary(glm(use2 ~ shuttle$wind, family = binomial))
summary(glm(1 - use2 ~ shuttle$wind, family = binomial))
summary(glm(1 - use2 ~ shuttle$wind, family = poisson))
exp(.031)
exp(-0.031)
data(InsectSprays)
head(InsectSprays)
?InsectSprays)
?InsectSprays
glm(count ~ spray, data = InsectSprays, family = poisson)
summary(glm(count ~ spray, data = InsectSprays, family = poisson))
exp(0.05588)
exp(-0.05588)
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
count <- rnorm(0, 5)
glm(count ~ x + offset(y), family = poisson)
count <- rnorm(0, 10)
glm(count ~ x + offset(y), family = poisson)
count
?rnorm
count <- rnorm(10, 0, 3)
glm(count ~ x + offset(y), family = poisson)
length(x)
count <- rnorm(11, 0, 3)
glm(count ~ x + offset(y), family = poisson)
count <- rnorm(11, 20, 3)
glm(count ~ x + offset(y), family = poisson)
y2 <-  log(10) + y
glm(count ~ x + offset(y2), family = poisson)
log(10)
knots <- 0
splineTerms <- sapply(knots, function(knot) (x > knot) * (x < knot))
xMat <- cbind(1, x, splineTerms)
lm(y ~ xMat - 1)
lm(y ~ xMat)
summary(lm(y ~ xMat))
plot(x, y)
summary(glm(use ~ wind + magn, data = shuttle, family = binomial))
exp(-3.201e-02)
summary(glm(use2 ~ wind + magn, data = shuttle, family = binomial))
install.packages("DBI")
library(DBI)
?DBI
library(RMySQL)
?dbConnect
install.packages("shiny")
library(shiny)
?library
?caret
install.packages("caret")
library(caret)
?caret
??caret
rox <- read.csv(file.choose())
head(rox)
home <- rox[home == "COL"]
home <- rox[rox$home == "COL",]
?attach
sum(home$home_hr)
home_ratio <- (sum(home$home_hr) + sum(home$visitor_hr)) / (sum(home$home_ab) + sum(home$visitor_ab))
home_ratio
away <- rox[rox$visitor == "COL"]
away <- rox[rox$visitor == "COL",]
away_ratio <- (sum(away$home_hr) + sum(away$visitor_hr)) / (sum(away$home_ab) + sum(away$visitor_ab))
home_ratio / away_ratio
?plyr
install.packages("plyr")
library(plyr)
?within
pf_all <- read.csv(file.choose())
head(pf_all)
type(pf_all)
?type
typeof(pf_all)
typeof(pf_all$home)
typeof(pf_all$visitor)
?gsub
pf_all$home <- gsub("FLO", "MIA", pf_all$home)
pf_all$visitor <- gsub("FLO", "MIA", pf_all$visitor)
pf_stat_teams <- function(stat, data, season_year=2013) {
data <- data[data$year == season_year,]
home_stat <- paste("home", stat, sep = "_")
vis_stat <- paste("visitor", stat, sep = "_")
pf_stat <- paste("pf", stat, season_year, sep="_")
cols = c(home_stat, visitor_stat, "home_ab", "visitor_ab")
cols <- c(home_stat, vis_stat, "home_ab", "visitor_ab")
park_sums <- ddply(data, .(home), colwise(sum, cols))
away_sums <- ddply(data, .(visitor), colwise(sum, cols))
visitor_stat <- paste("visitor", stat, sep = "_")
cols = c(home_stat, visitor_stat, "home_ab", "visitor_ab") park_sums <- ddply(data, .(home), colwise(sum, cols))
+
+ away_sums <- ddply(data, .(visitor), colwise(sum, cols))
pf_stat_teams <- function(stat, data, season_year=2013) {
data <- subset(data, year == season_year)
home_stat = paste("home", stat, sep="_")
visitor_stat = paste("visitor", stat, sep="_")
pf_stat = paste("pf", stat, season_year, sep="_")
cols = c(home_stat, visitor_stat, "home_ab", "visitor_ab")
park_sums <- ddply(data, .(home), colwise(sum, cols))
away_sums <- ddply(data, .(visitor), colwise(sum, cols))
park_sums$park_ratio <- (park_sums[[home_stat]] + park_sums[[visitor_stat]]) / (park_sums[["home_ab"]] + park_sums[["visitor_ab"]])
away_sums$away_ratio <- (away_sums[[home_stat]] + away_sums[[visitor_stat]]) / (away_sums[["home_ab"]] + away_sums[["visitor_ab"]])
pf <- merge(park_sums, away_sums, by.x="home", by.y="visitor")
pf[[pf_stat]] <- with(pf, pf$park_ratio / pf$away_ratio)
pf <- rename(pf, replace=c("home" = "team"))
pf <- subset(pf, select = c("team", pf_stat))
return(pf)
}
hr_2013 <- pf_stat_teams("hr", pf_all, season_year=2013)
hr_2013
2b_2013 <- pf_stat_teams("hr", pf_all, season_year=2013)
doubles_2013 <- pf_stat_teams("hr", pf_all, season_year=2013)
doubles_2013
walks_2013 <- pf_stat_teams("hr", pf_all, season_year=2013)
walks_2013
walks_2013 <- pf_stat_teams("bb", pf_all, season_year=2013)
walks_2013
min(walks_2013)
min(walks_2013[,2])
which.min(walks_2013[,2])
which.max(walks_2013[,2])
doubles_2013 <- pf_stat_teams("2b", pf_all, season_year=2013)
which.min(doubles_2013[,2])
doubles_2013[23]
doubles_2013[23,]
doubles_2013 <- pf_stat_teams("2b", pf_all, season_year=2010)
which.min(doubles_2013[,2])
install.packages("outliers")
library(outliers)
qdixon(14, 76, 82, 36, 85)
qdixon(c(14, 76, 82, 36, 85))
?qdixon
?gap
?qtable
qtable(c(14, 76, 82, 36, 85))
# Import data
year_team <- read.csv(file.choose())
# Calculate AVG, SLG, OPS; then insert into data frame
year_team$AVG <- with(year_team, (H/(AB)))
year_team$OBP <- with(year_team, ((H+BB+HBP)/(AB+BB+HBP+SF)))
year_team$SLG <- with(year_team, ((H+X2B+2*X3B+3*HR)/(AB)))
year_team$OPS <- with(year_team, OBP + SLG)
# Correlation Plot Function
# Draws a scatter plot of 2 variables from a dataframe
# displaying a best-fit line and R^2 value in the legend
corr_plot <- function(v1, v2, df) {
plot(df[[v1]], df[[v2]], xlab=v1, ylab=v2) # Draw scatter Plot
linfit <- lm(df[[v2]]~df[[v1]]) # Calculate best-fit line
abline(linfit) # Draw best-fit line
# Add R^2 value in legend
legend("topleft", legend = paste("R^2:", signif(summary(linfit)$r.squared, 4)))
}
# Add 1B for calculation simplicity
year_team$X1B <- with(year_team, H-X2B-X3B-HR)
# First we'll only use different types of hits
lin_basic_weights <- lm(R ~ X1B + X2B + X3B + HR, data=year_team)
# Apply model's coefficients to predict past runs
year_team$linRBasic <- predict(lin_basic_weights)
# Now let's add in BB, HBP, and SB to improve the regression's accuracy.
lin_more_weights <- lm(R ~ X1B + X2B + X3B + HR + I(BB + HBP) + SB, data=year_team)
year_team$linRMore <- predict(lin_more_weights)
#running correlation plots
corr_plot('HR', 'HR', year_team)
corr_plot('HR', 'HBP', year_team)
corr_plot('SF', 'R', year_team)
head(year_team)
corr_plot("linRMore", "R", year_team)
corr_plot("linRBasic", "R", year_team)
corr_plot("OPS", "R", year_team)
install.packages("devtools")
library(devtools)
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
data(concrete)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
?cut2
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
?cut2
head(mixtures)
head(training)
plot(1:nrow(mixtures), mixtures$CompressiveStrength, color = mixtures$FlyAsh)
plot(1:nrow(mixtures), mixtures$CompressiveStrength, color = mixtures$age)
?plot
plot(1:nrow(mixtures), mixtures$CompressiveStrength, color = rainbow(mixtures$age))
?rainbow
?heat.colors
plot(1:nrow(mixtures), mixtures$CompressiveStrength, color = rainbow(12))
data <- iris
plot(data$Sepal.Length, data$Sepal.Width, col=data$Species)
library(ggplot2)
qplot(Sepal.Length, Sepal.Width, data=iris, colour=Species)
qplot(1:nrow(mixtures), CompressiveStrength, data = mixtures, color = factor(FlyAsh))
qplot(1:nrow(mixtures), CompressiveStrength, data = mixtures, color = factor(Age))
qplot(1:nrow(mixtures), CompressiveStrength, data = mixtures, color = factor(FlyAsh))
?cut2
ash = cut2(mixtures$FlyAsh, g = 10)
qplot(1:nrow(mixtures), CompressiveStrength, data = mixtures, color = factor(ash))
qplot(FlyAsh, CompressiveStrength, data = mixtures)
qplot(Age, CompressiveStrength, data = mixtures)
qplot(SuperPlasticizer, data = mixtures)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(SuperPlasticizer, data = mixtures)
head(mixtures)
qplot(Superplasticizer, data = mixtures)
qplot(log(Superplasticizer+1), data = mixtures)
qplot(Superplasticizer, data = mixtures)
?log
qplot(log(Superplasticizer+1), data = mixtures)
new <- mixtures$Superplasticizer + 1
head(new)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
colnames(training)
IL <- grepl("^IL",colnames(training))
sum(IL)
IL_subset <- training[,IL]
head(training)
head(IL)
head(IL_subset)
?preProcess
preProcess(IL_subset, thresh = .9)
processed <- preProcess(IL_subset, thresh = 0.9)
processed
summary(processed)
processed$knnSummary
processed$thresh
processed$dim
processed$pcaComp
library(shiny)
?shiny
2^4
setwd("~/Coursera Data Science/Data Products")
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
a <- "hello"
a[2:5]
?cut
runApp()
library(devtools)
library(Rtools)
install.packages("Rtools")
shinyapps::setAccountInfo(
name="silverstats",
token="005A4589CC5A354BB23BB6FCEF69E68A",
secret="ey8IMr2cvZYd7kEXFndYMiJbvIn1NcOZmVJuGeSc")
install.packages("shinyapps")
install.packages("shinyapps")
install.packages("devtools")
if (!require("devtools"))
install.packages("devtools")
devtools::install_github("rstudio/shinyapps")
shinyapps::setAccountInfo(
name="silverstats",
token="005A4589CC5A354BB23BB6FCEF69E68A",
secret="ey8IMr2cvZYd7kEXFndYMiJbvIn1NcOZmVJuGeSc")
runApp()
deployApp()
library(shinyapps)
deployApp()
?deployApp
deployApp(appName = "Pythagorean Expectation")
deployApp(appName = "Pythagorean")
install.packages("slidify")
install.packages("list")
library(slidify)
author("Pythagorean")
?slidify
?knit
?browseURL
a = 1; b = 2
a
b
head(runs)
runs <- read.csv("runs.csv")
runs$Pythag <- (runs$R^2)/(runs$R^2 + runs$RA^2)
cor(runs$Pythag, runs$WPct)
?abline
publish(user = "SilverStats", repo = "Pythagorean")
publish(title = 'Pythagorean', 'index.html', host = 'rpubs')
publish(user = "SilverStats", repo = "Pythagorean")
?publish
git init
publish(user = "SilverStats", repo = "Pythagorean")
